{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a8eb05fc2f2d4894bc37e8c35a932ba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58d52a2e345f46e9a33b21d36e678a9e",
              "IPY_MODEL_565783ec3b86424ba7813988d60559ac",
              "IPY_MODEL_a82dbc35eb08417eb84ee66150338222"
            ],
            "layout": "IPY_MODEL_aacef468e5f742b7a530298ee361d277"
          }
        },
        "58d52a2e345f46e9a33b21d36e678a9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fc905d26044400fa2cc5d98fa8af606",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_22a7ed802a2a4acc8ea4c8244ed41a11",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "565783ec3b86424ba7813988d60559ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18cb6a0cdffa49a890c38336ff5daf4e",
            "max": 1115567652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec4e9a874139429593efb16b7cdc9640",
            "value": 1115567652
          }
        },
        "a82dbc35eb08417eb84ee66150338222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbfe7180c80b4028a9a9cb60f7a6cfab",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a6956a0e2c344ce8a17af73bef938911",
            "value": "‚Äá1.12G/1.12G‚Äá[00:09&lt;00:00,‚Äá226MB/s]"
          }
        },
        "aacef468e5f742b7a530298ee361d277": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fc905d26044400fa2cc5d98fa8af606": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22a7ed802a2a4acc8ea4c8244ed41a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18cb6a0cdffa49a890c38336ff5daf4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec4e9a874139429593efb16b7cdc9640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fbfe7180c80b4028a9a9cb60f7a6cfab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6956a0e2c344ce8a17af73bef938911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shahriarin2garden/fake-news/blob/main/FakeNewsDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train=pd.read_csv(\"/content/Fake_train (1).csv\")\n",
        "train2=pd.read_csv(\"/content/Fake_dev.csv\")"
      ],
      "metadata": {
        "id": "CJcyHL3tkgGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect\n",
        "!pip install langid\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXStFYz0l1kR",
        "outputId": "846c5d14-5aa4-475c-925c-0181bf0ef4d2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m512.0/981.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=d02708b2442594ec8e192c081462ebe200ef2acc2b53a4161f1ee9ab9eea6650\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n",
            "Collecting langid\n",
            "  Downloading langid-1.1.6.tar.gz (1.9 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from langid) (1.26.4)\n",
            "Building wheels for collected packages: langid\n",
            "  Building wheel for langid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langid: filename=langid-1.1.6-py3-none-any.whl size=1941171 sha256=b43552cd82fdf8d5f44d72ae2e8317e11689f9fff15618e7ecc3adb489955707\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/6a/b6/b7eb43a6ad55b139c15c5daa29f3707659cfa6944d3c696f5b\n",
            "Successfully built langid\n",
            "Installing collected packages: langid\n",
            "Successfully installed langid-1.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from langdetect import detect, DetectorFactory\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "# Set seed for consistent results\n",
        "# DetectorFactory.seed = 0\n",
        "\n",
        "# Load dataset (replace `train` with your actual DataFrame)\n",
        "data = train\n",
        "\n",
        "# Handle missing or null values in the text column\n",
        "data['text'] = data['text'].fillna('')\n",
        "\n",
        "# Function to safely detect language\n",
        "def safe_detect(text):\n",
        "    try:\n",
        "        # Skip detection for empty strings or strings with no alphanumeric characters\n",
        "        if not text.strip() or not any(char.isalnum() for char in text):\n",
        "            return \"unknown\"\n",
        "        return detect(text)\n",
        "    except Exception:\n",
        "        return \"error\"  # Return \"error\" for texts that cause issues\n",
        "\n",
        "# Apply language detection\n",
        "data['language'] = data['text'].apply(safe_detect)\n",
        "\n",
        "# Find unique languages detected\n",
        "unique_languages = data['language'].unique()\n",
        "\n",
        "# Output the unique languages\n",
        "print(\"Unique languages detected:\", unique_languages)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNAY7jFrke7N",
        "outputId": "eb13c2b7-a2da-4421-a38d-38f75fea3266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique languages detected: ['error' 'unknown']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch scikit-learn pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgnvMzz_lEeF",
        "outputId": "2742799a-54b2-460d-8efc-28bbb9e7bf1d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "J2xxdW9VmDSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for empty texts\n",
        "print(f\"Before removing empty texts: {len(data)} rows\")\n",
        "\n",
        "# Filter out rows where the 'Text' column is empty or contains only whitespace\n",
        "data = data[data['text'].str.strip().astype(bool)]\n",
        "train2 = train2[train2['text'].str.strip().astype(bool)]\n",
        "\n",
        "# Check the number of rows after removal\n",
        "print(f\"After removing empty texts: {len(data)} rows\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Zu4tqwkmM38",
        "outputId": "62b93c45-b2b5-41cd-81db-27a46a3608d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before removing empty texts: 3257 rows\n",
            "After removing empty texts: 3257 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Function to remove emojis\n",
        "def remove_emojis(text):\n",
        "    emoji_pattern = re.compile(\n",
        "        \"[\"\n",
        "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        \"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "        \"\\U00002702-\\U000027B0\"\n",
        "        \"\\U00002702-\\U000027B0\"\n",
        "        \"\\U000024C2-\\U0001F251\"\n",
        "        \"]+\",\n",
        "        flags=re.UNICODE,\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    -\n",
        "    return emoji_pattern.sub(r\"\", text)\n"
      ],
      "metadata": {
        "id": "paXwX7ifmP2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "def preprocess_text(text):\n",
        "    # Remove emojis\n",
        "    text = remove_emojis(text)\n",
        "    # Lowercase the text\n",
        "    text = text.lower()\n",
        "    # Remove URLs\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
        "    # Remove special characters and punctuation\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "cFz27HJomS9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocessing\n",
        "data['text'] = data['text'].apply(preprocess_text)\n",
        "train2['text'] = train2['text'].apply(preprocess_text)\n",
        "\n"
      ],
      "metadata": {
        "id": "Lh2S1uVcmXqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['label'] = data['label'].map({'Fake': 0, 'original': 1})\n",
        "# Encode labels\n",
        "train2['label'] = train2['label'].map({'Fake': 0, 'original': 1})  # Encode labels"
      ],
      "metadata": {
        "id": "XUwHRc_gmajh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "GHLwyQNCmbnr",
        "outputId": "34620d8f-bce9-4234-81ff-e59765e8bfbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "1    1658\n",
              "0    1599\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1599</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'data' is your DataFrame and 'label' is the column with class labels.\n",
        "\n",
        "# Separate classes\n",
        "class_1 = data[data['label'] == 1]  # Majority class\n",
        "class_0 = data[data['label'] == 0]  # Minority class\n",
        "\n",
        "# Upsample minority class (class_0) to match class_1\n",
        "class_0_upsampled = resample(class_0,\n",
        "                             replace=True,  # Allow duplicates\n",
        "                             n_samples=len(class_1),  # Match the majority class size\n",
        "                             random_state=42)\n",
        "\n",
        "# Combine both classes\n",
        "balanced_data = pd.concat([class_1, class_0_upsampled])\n",
        "\n",
        "# Shuffle the dataset\n",
        "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Print the label counts to confirm balance\n",
        "print(balanced_data['label'].value_counts())\n",
        "\n",
        "# Optional: Save the balanced dataset to a new file\n",
        "# balanced_data.to_csv('balanced_data.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UAN_MPwiky6",
        "outputId": "c0b42290-0488-40eb-d8f4-c90f79bacf97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "0    1658\n",
            "1    1658\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
        "\n",
        "# Tokenize data\n",
        "def tokenize_data(texts, labels=None):\n",
        "    tokenized = tokenizer(list(texts), padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "    if labels is not None:\n",
        "        tokenized['labels'] = torch.tensor(labels)\n",
        "    return tokenized"
      ],
      "metadata": {
        "id": "v6Pkfz0fmhGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=data['text']\n",
        "X_test=train2['text']\n",
        "y_train=data['label']\n",
        "y_test=train2['label']"
      ],
      "metadata": {
        "id": "wdEfSv2Bmh1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenize_data(X_train, y_train)\n",
        "test_encodings = tokenize_data(X_test, y_test)"
      ],
      "metadata": {
        "id": "E-9IaWdPmoL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FakeNewsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: tensor[idx] for key, tensor in self.encodings.items()}\n",
        "\n",
        "train_dataset = FakeNewsDataset(train_encodings)\n",
        "test_dataset = FakeNewsDataset(test_encodings)"
      ],
      "metadata": {
        "id": "uh8X_hMqmrq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "BndnKoFamstO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=2).to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "a8eb05fc2f2d4894bc37e8c35a932ba3",
            "58d52a2e345f46e9a33b21d36e678a9e",
            "565783ec3b86424ba7813988d60559ac",
            "a82dbc35eb08417eb84ee66150338222",
            "aacef468e5f742b7a530298ee361d277",
            "7fc905d26044400fa2cc5d98fa8af606",
            "22a7ed802a2a4acc8ea4c8244ed41a11",
            "18cb6a0cdffa49a890c38336ff5daf4e",
            "ec4e9a874139429593efb16b7cdc9640",
            "fbfe7180c80b4028a9a9cb60f7a6cfab",
            "a6956a0e2c344ce8a17af73bef938911"
          ]
        },
        "id": "y8zPj40omxIY",
        "outputId": "59f7954a-9769-4130-9926-b1512ca984bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8eb05fc2f2d4894bc37e8c35a932ba3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model and tokenizer names\n",
        "    models = {\n",
        "        \"IndicBERT\": (\"ai4bharat/indic-bert\", \"ai4bharat/indic-bert\"),\n",
        "        \"mBERT\": (\"bert-base-multilingual-cased\", \"bert-base-multilingual-cased\"),\n",
        "        \"XLM-RoBERTa\": (\"xlm-roberta-base\", \"xlm-roberta-base\")  # Include the original model for comparison\n",
        "    }\n",
        "\n",
        "    # Train and evaluate each model\n",
        "    results = {}\n",
        "    for model_name, (model_path, tokenizer_path) in models.items():\n",
        "        print(f\"Training and evaluating {model_name}...\")\n",
        "        report = train_and_evaluate_model(model_path, tokenizer_path, train_dataset, test_dataset)\n",
        "        results[model_name] = report\n",
        "\n",
        "    # Print the results\n",
        "    for model_name, report in results.items():\n",
        "        print(f\"--- {model_name} ---\")\n",
        "        print(report)  # This will print the classification report for each model\n",
        ""
      ],
      "metadata": {
        "id": "7L39YUdO3o1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',                 # Directory to save model checkpoints\n",
        "    evaluation_strategy=\"epoch\",           # Evaluate after every epoch\n",
        "    save_strategy=\"epoch\",                 # Save checkpoints after every epoch\n",
        "    logging_dir='./logs',                  # Directory for logging\n",
        "    learning_rate=5e-4,                    # Learning rate\n",
        "    per_device_train_batch_size=8,         # Training batch size\n",
        "    per_device_eval_batch_size=8,          # Evaluation batch size\n",
        "    num_train_epochs=3,                    # Number of epochs\n",
        "    weight_decay=0.01,                     # Weight decay\n",
        "    load_best_model_at_end=True,           # Load the best model at the end\n",
        "    logging_steps=10,                      # Log every 10 steps\n",
        "    save_total_limit=1,                    # Keep only the best model checkpoint\n",
        "    metric_for_best_model=\"eval_loss\",     # Use evaluation loss to determine the best model\n",
        "    greater_is_better=False                # Lower eval loss is better\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ddz-oQmlm5Ru",
        "outputId": "a5bb85ba-40bd-4bac-ba66-f391516f9fdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "fvvYkZGcm8Pu",
        "outputId": "002d62c8-de41-4ee3-b500-f8bf252289ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250127_151639-zk21f2hg</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mehrah1103-aaa/huggingface/runs/zk21f2hg' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/mehrah1103-aaa/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mehrah1103-aaa/huggingface' target=\"_blank\">https://wandb.ai/mehrah1103-aaa/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mehrah1103-aaa/huggingface/runs/zk21f2hg' target=\"_blank\">https://wandb.ai/mehrah1103-aaa/huggingface/runs/zk21f2hg</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1225' max='1224' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1224/1224 17:41, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.691400</td>\n",
              "      <td>0.694274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.740100</td>\n",
              "      <td>0.698050</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1224' max='1224' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1224/1224 18:58, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.691400</td>\n",
              "      <td>0.694274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.740100</td>\n",
              "      <td>0.698050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.685600</td>\n",
              "      <td>0.693656</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1224, training_loss=0.7110574876560884, metrics={'train_runtime': 1281.769, 'train_samples_per_second': 7.623, 'train_steps_per_second': 0.955, 'total_flos': 2570858121922560.0, 'train_loss': 0.7110574876560884, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = trainer.predict(test_dataset)\n",
        "y_pred = torch.argmax(torch.tensor(predictions.predictions), axis=1).numpy()\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "qasGwYjAm_Op",
        "outputId": "e7da805c-0524-4531-b321-4236f46d3b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       406\n",
            "           1       0.50      1.00      0.67       409\n",
            "\n",
            "    accuracy                           0.50       815\n",
            "   macro avg       0.25      0.50      0.33       815\n",
            "weighted avg       0.25      0.50      0.34       815\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from torch.cuda.amp import autocast\n",
        "\n",
        "# Define the paths\n",
        "model_checkpoint = \"/content/results/checkpoint-1224\"\n",
        "base_model = \"xlm-roberta-base\"  # Replace with the base model you used during training\n",
        "\n",
        "# Load the tokenizer from the base model\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "\n",
        "# Load the fine-tuned model from the best checkpoint\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n",
        "\n",
        "# Load the test data\n",
        "test_data = pd.read_csv(\"/content/Fake_test_without_labels.csv\")  # Replace with your test data file\n",
        "texts = test_data[\"text\"].fillna(\"\").tolist()  # Handle empty or NaN text entries\n",
        "\n",
        "# Tokenize the test data\n",
        "test_encodings = tokenizer(\n",
        "    texts,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=512,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# Move the model to the device (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Make predictions\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Use mixed precision to reduce memory usage if on GPU\n",
        "with torch.no_grad():\n",
        "    predicted_labels = []\n",
        "    for i in range(0, len(texts), 16):  # Change 16 to your batch size\n",
        "        batch_texts = texts[i:i+16]\n",
        "        batch_encodings = tokenizer(\n",
        "            batch_texts,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        inputs = {key: val.to(device) for key, val in batch_encodings.items()}\n",
        "\n",
        "        with autocast():  # Use mixed precision if on GPU\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            batch_predictions = torch.argmax(logits, dim=1).cpu().numpy()  # Get predicted labels\n",
        "            predicted_labels.extend(batch_predictions)\n",
        "\n",
        "        # Empty cache after each batch if needed\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "# Map predicted labels to \"Fake\" or \"Original\"\n",
        "label_mapping = {0: \"Fake\", 1: \"Original\"}\n",
        "test_data[\"label\"] = [label_mapping[label] for label in predicted_labels]\n",
        "\n",
        "# Save the results\n",
        "test_data.to_csv(\"VEL_Tamil_task1.csv\", index=False)\n",
        "\n",
        "# Preview the results\n",
        "print(test_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVwJXcgRiYf_",
        "outputId": "20b7f745-c807-4e47-be45-a43c29977283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-9864ac077965>:50: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Use mixed precision if on GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Id                                               text     label\n",
            "0  Fake_01  5000 ‡¥â‡¥≥‡µç‡¥≥ ‡¥™‡µã‡µæ  ‡¥≤‡µã‡¥ó‡µç‚Äå‡¥°‡µç‚Äå‡¥µ‡µª ‡¥á‡¥™‡µç‡¥™‡µã‡¥≥‡µç 250000 ‡¥é‡¥®‡µç‡¥§‡¥æ...  Original\n",
            "1  Fake_02  ‡¥ì‡¥∑‡µã ‡¥∞‡¥ú‡¥®‡µÄ‡¥∑‡µç  ‡¥™‡¥±‡¥û‡µç‡¥û‡¥™‡µã‡¥≤‡µÜ  ‡¥é‡¥®‡¥ø‡¥ï‡µç‡¥ï‡¥™‡µç‡¥™‡µã‡µæ ‡¥§‡µã‡¥®‡µç‡¥®‡¥ø‡¥Ø‡¥§‡µç ‡¥Ö...  Original\n",
            "2  Fake_03  ‡¥ö‡µá‡¥ü‡µç‡¥ü‡¥æ  ‡¥µ‡¥æ‡µº‡¥§‡µç‡¥§  ‡¥µ‡¥Ø‡µç‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥®‡¥§‡µç  ‡¥ï‡µá‡¥∞‡¥≥‡¥§‡µç‡¥§‡¥ø‡¥≤‡¥æ‡¥£‡µç  ‡¥∏‡¥Ç...  Original\n",
            "3  Fake_04             Shame for entire Woman&#39;s of Kerala  Original\n",
            "4  Fake_05  135 code janaghal andhu wide business cheythal...  Original\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cgDY0FhDpVA4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}