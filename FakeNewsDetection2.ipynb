{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shahriarin2garden/fake-news/blob/main/FakeNewsDetection2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train=pd.read_csv(\"/content/Fake_train (1).csv\")\n",
        "train2=pd.read_csv(\"/content/Fake_dev.csv\")"
      ],
      "metadata": {
        "id": "CJcyHL3tkgGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect\n",
        "!pip install langid\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXStFYz0l1kR",
        "outputId": "846c5d14-5aa4-475c-925c-0181bf0ef4d2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.0/981.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=d02708b2442594ec8e192c081462ebe200ef2acc2b53a4161f1ee9ab9eea6650\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n",
            "Collecting langid\n",
            "  Downloading langid-1.1.6.tar.gz (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from langid) (1.26.4)\n",
            "Building wheels for collected packages: langid\n",
            "  Building wheel for langid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langid: filename=langid-1.1.6-py3-none-any.whl size=1941171 sha256=b43552cd82fdf8d5f44d72ae2e8317e11689f9fff15618e7ecc3adb489955707\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/6a/b6/b7eb43a6ad55b139c15c5daa29f3707659cfa6944d3c696f5b\n",
            "Successfully built langid\n",
            "Installing collected packages: langid\n",
            "Successfully installed langid-1.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from langdetect import detect, DetectorFactory\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "# Set seed for consistent results\n",
        "# DetectorFactory.seed = 0\n",
        "\n",
        "# Load dataset (replace `train` with your actual DataFrame)\n",
        "data = train\n",
        "\n",
        "# Handle missing or null values in the text column\n",
        "data['text'] = data['text'].fillna('')\n",
        "\n",
        "# Function to safely detect language\n",
        "def safe_detect(text):\n",
        "    try:\n",
        "        # Skip detection for empty strings or strings with no alphanumeric characters\n",
        "        if not text.strip() or not any(char.isalnum() for char in text):\n",
        "            return \"unknown\"\n",
        "        return detect(text)\n",
        "    except Exception:\n",
        "        return \"error\"  # Return \"error\" for texts that cause issues\n",
        "\n",
        "# Apply language detection\n",
        "data['language'] = data['text'].apply(safe_detect)\n",
        "\n",
        "# Find unique languages detected\n",
        "unique_languages = data['language'].unique()\n",
        "\n",
        "# Output the unique languages\n",
        "print(\"Unique languages detected:\", unique_languages)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNAY7jFrke7N",
        "outputId": "eb13c2b7-a2da-4421-a38d-38f75fea3266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique languages detected: ['error' 'unknown']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch scikit-learn pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgnvMzz_lEeF",
        "outputId": "2742799a-54b2-460d-8efc-28bbb9e7bf1d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "J2xxdW9VmDSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for empty texts\n",
        "print(f\"Before removing empty texts: {len(data)} rows\")\n",
        "\n",
        "# Filter out rows where the 'Text' column is empty or contains only whitespace\n",
        "data = data[data['text'].str.strip().astype(bool)]\n",
        "train2 = train2[train2['text'].str.strip().astype(bool)]\n",
        "\n",
        "# Check the number of rows after removal\n",
        "print(f\"After removing empty texts: {len(data)} rows\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Zu4tqwkmM38",
        "outputId": "62b93c45-b2b5-41cd-81db-27a46a3608d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before removing empty texts: 3257 rows\n",
            "After removing empty texts: 3257 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Function to remove emojis\n",
        "def remove_emojis(text):\n",
        "    emoji_pattern = re.compile(\n",
        "        \"[\"\n",
        "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        \"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "        \"\\U00002702-\\U000027B0\"\n",
        "        \"\\U00002702-\\U000027B0\"\n",
        "        \"\\U000024C2-\\U0001F251\"\n",
        "        \"]+\",\n",
        "        flags=re.UNICODE,\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    -\n",
        "    return emoji_pattern.sub(r\"\", text)\n"
      ],
      "metadata": {
        "id": "paXwX7ifmP2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "def preprocess_text(text):\n",
        "    # Remove emojis\n",
        "    text = remove_emojis(text)\n",
        "    # Lowercase the text\n",
        "    text = text.lower()\n",
        "    # Remove URLs\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
        "    # Remove special characters and punctuation\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "cFz27HJomS9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocessing\n",
        "data['text'] = data['text'].apply(preprocess_text)\n",
        "train2['text'] = train2['text'].apply(preprocess_text)\n",
        "\n"
      ],
      "metadata": {
        "id": "Lh2S1uVcmXqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['label'] = data['label'].map({'Fake': 0, 'original': 1})\n",
        "# Encode labels\n",
        "train2['label'] = train2['label'].map({'Fake': 0, 'original': 1})  # Encode labels"
      ],
      "metadata": {
        "id": "XUwHRc_gmajh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "GHLwyQNCmbnr",
        "outputId": "34620d8f-bce9-4234-81ff-e59765e8bfbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "1    1658\n",
              "0    1599\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1599</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'data' is your DataFrame and 'label' is the column with class labels.\n",
        "\n",
        "# Separate classes\n",
        "class_1 = data[data['label'] == 1]  # Majority class\n",
        "class_0 = data[data['label'] == 0]  # Minority class\n",
        "\n",
        "# Upsample minority class (class_0) to match class_1\n",
        "class_0_upsampled = resample(class_0,\n",
        "                             replace=True,  # Allow duplicates\n",
        "                             n_samples=len(class_1),  # Match the majority class size\n",
        "                             random_state=42)\n",
        "\n",
        "# Combine both classes\n",
        "balanced_data = pd.concat([class_1, class_0_upsampled])\n",
        "\n",
        "# Shuffle the dataset\n",
        "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Print the label counts to confirm balance\n",
        "print(balanced_data['label'].value_counts())\n",
        "\n",
        "# Optional: Save the balanced dataset to a new file\n",
        "# balanced_data.to_csv('balanced_data.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UAN_MPwiky6",
        "outputId": "c0b42290-0488-40eb-d8f4-c90f79bacf97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "0    1658\n",
            "1    1658\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
        "\n",
        "# Tokenize data\n",
        "def tokenize_data(texts, labels=None):\n",
        "    tokenized = tokenizer(list(texts), padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "    if labels is not None:\n",
        "        tokenized['labels'] = torch.tensor(labels)\n",
        "    return tokenized"
      ],
      "metadata": {
        "id": "v6Pkfz0fmhGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=data['text']\n",
        "X_test=train2['text']\n",
        "y_train=data['label']\n",
        "y_test=train2['label']"
      ],
      "metadata": {
        "id": "wdEfSv2Bmh1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenize_data(X_train, y_train)\n",
        "test_encodings = tokenize_data(X_test, y_test)"
      ],
      "metadata": {
        "id": "E-9IaWdPmoL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FakeNewsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: tensor[idx] for key, tensor in self.encodings.items()}\n",
        "\n",
        "train_dataset = FakeNewsDataset(train_encodings)\n",
        "test_dataset = FakeNewsDataset(test_encodings)"
      ],
      "metadata": {
        "id": "uh8X_hMqmrq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "BndnKoFamstO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model and tokenizer names\n",
        "    models = {\n",
        "        \"IndicBERT\": (\"ai4bharat/indic-bert\", \"ai4bharat/indic-bert\"),\n",
        "        \"mBERT\": (\"bert-base-multilingual-cased\", \"bert-base-multilingual-cased\"),\n",
        "        \"XLM-RoBERTa\": (\"xlm-roberta-base\", \"xlm-roberta-base\")  # Include the original model for comparison\n",
        "    }\n",
        "\n",
        "    # Train and evaluate each model\n",
        "    results = {}\n",
        "    for model_name, (model_path, tokenizer_path) in models.items():\n",
        "        print(f\"Training and evaluating {model_name}...\")\n",
        "        report = train_and_evaluate_model(model_path, tokenizer_path, train_dataset, test_dataset)\n",
        "        results[model_name] = report\n",
        "\n",
        "    # Print the results\n",
        "    for model_name, report in results.items():\n",
        "        print(f\"--- {model_name} ---\")\n",
        "        print(report)  # This will print the classification report for each model\n"
      ],
      "metadata": {
        "id": "7L39YUdO3o1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from torch.cuda.amp import autocast\n",
        "\n",
        "# Define the paths\n",
        "model_checkpoint = \"/content/results/checkpoint-1224\"\n",
        "base_model = \"xlm-roberta-base\"  # Replace with the base model you used during training\n",
        "\n",
        "# Load the tokenizer from the base model\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "\n",
        "# Load the fine-tuned model from the best checkpoint\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n",
        "\n",
        "# Load the test data\n",
        "test_data = pd.read_csv(\"/content/Fake_test_without_labels.csv\")  # Replace with your test data file\n",
        "texts = test_data[\"text\"].fillna(\"\").tolist()  # Handle empty or NaN text entries\n",
        "\n",
        "# Tokenize the test data\n",
        "test_encodings = tokenizer(\n",
        "    texts,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=512,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# Move the model to the device (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Make predictions\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Use mixed precision to reduce memory usage if on GPU\n",
        "with torch.no_grad():\n",
        "    predicted_labels = []\n",
        "    for i in range(0, len(texts), 16):  # Change 16 to your batch size\n",
        "        batch_texts = texts[i:i+16]\n",
        "        batch_encodings = tokenizer(\n",
        "            batch_texts,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        inputs = {key: val.to(device) for key, val in batch_encodings.items()}\n",
        "\n",
        "        with autocast():  # Use mixed precision if on GPU\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            batch_predictions = torch.argmax(logits, dim=1).cpu().numpy()  # Get predicted labels\n",
        "            predicted_labels.extend(batch_predictions)\n",
        "\n",
        "        # Empty cache after each batch if needed\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "# Map predicted labels to \"Fake\" or \"Original\"\n",
        "label_mapping = {0: \"Fake\", 1: \"Original\"}\n",
        "test_data[\"label\"] = [label_mapping[label] for label in predicted_labels]\n",
        "\n",
        "# Save the results\n",
        "test_data.to_csv(\"VEL_Tamil_task1.csv\", index=False)\n",
        "\n",
        "# Preview the results\n",
        "print(test_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVwJXcgRiYf_",
        "outputId": "20b7f745-c807-4e47-be45-a43c29977283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-9864ac077965>:50: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Use mixed precision if on GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Id                                               text     label\n",
            "0  Fake_01  5000 ഉള്ള പോൾ  ലോഗ്‌ഡ്‌വൻ ഇപ്പോള് 250000 എന്താ...  Original\n",
            "1  Fake_02  ഓഷോ രജനീഷ്  പറഞ്ഞപോലെ  എനിക്കപ്പോൾ തോന്നിയത് അ...  Original\n",
            "2  Fake_03  ചേട്ടാ  വാർത്ത  വയ്ക്കുന്നത്  കേരളത്തിലാണ്  സം...  Original\n",
            "3  Fake_04             Shame for entire Woman&#39;s of Kerala  Original\n",
            "4  Fake_05  135 code janaghal andhu wide business cheythal...  Original\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cgDY0FhDpVA4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}